{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This data set contains images of digits 0 to 9 and we have to make predictions for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST/\",one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (5000, 784), (10000, 784))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape, mnist.validation.images.shape, mnist.test.images.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 784 implies 28*28 pixels flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ff407fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting a random image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "narr = np.array(mnist.train.images[7])\n",
    "reshaped_arr = narr.reshape(28,28)\n",
    "plt.imshow(reshaped_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising weights and biases using tf.random_normal(shape)\n",
    "# weights and biases are a dict with keys h1,h2,h3,out\n",
    "# We are planning to make a Neural network with 3 hidden layers before the actual output layer\n",
    "\n",
    "n_input = 784 # ofcourse features are 784.\n",
    "n_hidden1 = 200\n",
    "n_hidden2 = 200\n",
    "n_hidden3 = 200\n",
    "n_classes = 10\n",
    "\n",
    "weights = {\n",
    "    \"h1\": tf.Variable(tf.random_normal([n_input,n_hidden1])),\n",
    "    \"h2\": tf.Variable(tf.random_normal([n_hidden1,n_hidden2])),\n",
    "    \"h3\": tf.Variable(tf.random_normal([n_hidden2,n_hidden3])),\n",
    "    \"out\": tf.Variable(tf.random_normal([n_hidden3,n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"h1\": tf.Variable(tf.random_normal([n_hidden1])),\n",
    "    \"h2\": tf.Variable(tf.random_normal([n_hidden2])),\n",
    "    \"h3\": tf.Variable(tf.random_normal([n_hidden3])),\n",
    "    \"out\": tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward_propagationcode with random weights and biases\n",
    "\n",
    "def forward_prop(x, weights, biases):\n",
    "    input_hidden1 = tf.add(tf.matmul(x,weights[\"h1\"]),biases[\"h1\"])\n",
    "    output_hidden1 = tf.nn.relu(input_hidden1)\n",
    "    \n",
    "    input_hidden2 = tf.add(tf.matmul(output_hidden1,weights[\"h2\"]),biases[\"h2\"])\n",
    "    output_hidden2 = tf.nn.relu(input_hidden2)\n",
    "    \n",
    "    input_hidden3 = tf.add(tf.matmul(output_hidden2,weights[\"h3\"]),biases[\"h3\"])\n",
    "    output_hidden3 = tf.nn.relu(input_hidden3)\n",
    "    \n",
    "    output = tf.add(tf.matmul(output_hidden3,weights[\"out\"]),biases[\"out\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# making placeholders for x and y such that passing train,test data can be more flexible\n",
    "x = tf.placeholder(\"float\",[None,n_input])\n",
    "y = tf.placeholder(tf.int32,[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = forward_prop(x,weights,biases)\n",
    "predicted_values = tf.argmax(predictions,1)\n",
    "true_values = tf.argmax(y,1)\n",
    "\n",
    "# comparing above two\n",
    "true_predictions_count = tf.equal(predicted_values,true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6316, (55000, 784))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing dataset, we are getting an accuracy of around 10%\n",
    "\n",
    "preds,pred_val = sess.run([predictions,predicted_values],feed_dict = {x:mnist.train.images})\n",
    "true_val,true_pred = sess.run([true_values,true_predictions_count], feed_dict = {x:mnist.train.images,y:mnist.train.labels})\n",
    "\n",
    "true_pred.sum(), sess.run(x, feed_dict = {x:mnist.train.images}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there is function for calculating cost in tensor flow\n",
    "# calculates the cross entropy cost\n",
    "# whih we can calculate ourselves, using formula = -y(log h) - (1-y)log(1-h)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = predictions,labels = y))\n",
    "\n",
    "\n",
    "# cost is an array of dimension n_classes,1 \n",
    "# therefore calculating the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9647.9746"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when we re run this cell cost reduces everytime\n",
    "\n",
    "c, _ = sess.run([cost,optimize], feed_dict = {x:mnist.train.images,y:mnist.train.labels})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778.77\n",
      "5247.46\n",
      "4040.22\n",
      "2753.69\n",
      "1899.67\n",
      "1550.61\n",
      "1388.6\n",
      "1305.36\n",
      "1229.61\n",
      "1098.47\n",
      "947.819\n",
      "828.853\n",
      "739.749\n",
      "675.335\n",
      "637.594\n",
      "619.483\n",
      "604.035\n",
      "578.788\n",
      "542.739\n",
      "503.674\n",
      "468.489\n",
      "439.745\n",
      "416.083\n",
      "395.325\n",
      "375.998\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    c, _ = sess.run([cost,optimize], feed_dict = {x:mnist.train.images,y:mnist.train.labels})\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46907, (55000, 784))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds,pred_val = sess.run([predictions,predicted_values],feed_dict = {x:mnist.train.images})\n",
    "true_val,true_pred = sess.run([true_values,true_predictions_count], feed_dict = {x:mnist.train.images,y:mnist.train.labels})\n",
    "\n",
    "true_pred.sum(), sess.run(x, feed_dict = {x:mnist.train.images}).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying batch gradient descent if it gives better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer()) # initializing again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14717.036"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  calculating cost\n",
    "c,_ = sess.run([cost,optimize],feed_dict = {x:mnist.train.images,y:mnist.train.labels})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22285.0736912\n",
      "3113.50453427\n",
      "4233.68899647\n",
      "9006.07302768\n",
      "6271.95974965\n",
      "3201.32590255\n",
      "1392.75567162\n",
      "3936.17366666\n",
      "1653.8441568\n",
      "1964.48169455\n",
      "2122.7847118\n",
      "2474.91495361\n",
      "3246.32793082\n",
      "639.395067614\n",
      "2211.380207\n",
      "2276.70659843\n",
      "3201.56344789\n",
      "1005.57974983\n",
      "2651.45247102\n",
      "1198.58721075\n",
      "333.459863893\n",
      "956.939019632\n",
      "907.494348547\n",
      "1689.82392124\n",
      "882.870693177\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = mnist.train.num_examples // batch_size\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        c,_ = sess.run([cost,optimize],feed_dict = {x:batch_x,y:batch_y})\n",
    "        total_cost += c\n",
    "    print(total_cost) # note that this total cost is way different than the cost calculated above! its a summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39208, (55000, 784))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds,pred_val = sess.run([predictions,predicted_values],feed_dict = {x:mnist.train.images})\n",
    "true_val,true_pred = sess.run([true_values,true_predictions_count], feed_dict = {x:mnist.train.images,y:mnist.train.labels})\n",
    "\n",
    "true_pred.sum(), sess.run(x, feed_dict = {x:mnist.train.images}).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:\n",
    "\n",
    "1. forward propagation with random weights : 10% accuracy\n",
    "2. with optimizer:\n",
    "    a. schoastic gradient descent : 46/55% accuracy\n",
    "    b. batch gradient descent : 39/55 % accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
